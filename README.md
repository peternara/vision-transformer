# Vision Transformer #

Implementation of Vision Transformer (ViT) from [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Anonymous](https://openreview.net/forum?id=YicbFdNTTy)

Instead of using convolutional architecture, it instead adapts Transformer architecture used in NLP for use with image classification - taking advantage of better scalability of this architecture compared with convolutional architectures.

Around 95% accuracy on MNIST. More experiments to come.
